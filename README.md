# Learning AI Agents

This repository documents my journey in learning and building AI Agents from scratch. The goal is to not just train machine learning models, but to structure them into autonomous agents that can perceive their environment, make decisions, and act in a goal-oriented way â€” all inspired by the foundational principles from the book *Artificial Intelligence: A Modern Approach (AIMA)*.

---

## ğŸ§  What is an AI Agent?
An AI Agent is a system that:
- **Perceives** its environment via sensors (e.g., an image classifier for fundus scans)
- **Decides** what action to take (e.g., refer the patient, monitor, or do nothing)
- **Acts** using effectors or actuators (in our case, logging the decision, referring cases)
- Optionally receives **feedback** from the environment to improve over time

This repo takes the idea beyond just CNNs â€” into actual systems thinking: building complete agent loops.

---

## ğŸ¯ Project Objective
To build a decision-making AI agent that:
- Wraps a trained CNN model (for glaucoma or fundus disease detection)
- Implements a `perceive-decide-act` loop
- Simulates basic environment responses (reward, penalty, feedback)
- Evolves from a rule-based agent to more goal- or utility-based designs

---

## ğŸ§© Learning Milestones
| Phase | Topic | Status |
|-------|-------|--------|
| 1 | Understand AI agents from AIMA Ch. 2, 3, 4, 18 | âœ… In Progress |
| 2 | Build initial agent loop with CNN as sensor | â³ |
| 3 | Add decision logic + simple environment | â³ |
| 4 | Evaluate agent behavior vs. raw model | â³ |
| 5 | Extend agent intelligence (rewards, rules, memory) | â³ |

---

## ğŸ—‚ Repository Structure
```
learning-ai-agents/
â”‚
â”œâ”€â”€ README.md              # This document
â”œâ”€â”€ requirements.txt       # Python dependencies
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ glaucoma_cnn.pt    # Pretrained or custom model
â”‚
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ agent_loop.py      # Agent's main control logic
â”‚   â”œâ”€â”€ environment.py     # Simulated feedback or rule-based reward system
â”‚   â””â”€â”€ utils.py           # Helper functions for thresholds, logging
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ agent_demo.ipynb   # Notebook demo of agent on fundus images
â”‚
â””â”€â”€ data/
    â””â”€â”€ demo_images/       # Sample images for agent testing
```

---

## ğŸ›  Dependencies
- Python â‰¥ 3.8
- PyTorch
- NumPy, OpenCV, Matplotlib
- tqdm, pandas (for logs and analysis)

Install via:
```bash
pip install -r requirements.txt
```

---

## ğŸ”­ Future Work
- [ ] Add reward feedback from environment
- [ ] Use confidence calibration for utility-based decisions
- [ ] Explore learning-based policies (Q-learning, planning)
- [ ] Shift toward goal-directed and learning agents

---

## ğŸ“š References
- Russell & Norvig, "Artificial Intelligence: A Modern Approach"
- AIMA Python Code: [https://github.com/aimacode/aima-python](https://github.com/aimacode/aima-python)
- Retinal Fundus Data: Kaggle datasets

---

## âœï¸ Author
This is a solo learning + building project by an MCA final semester student interested in applied vision AI and autonomous intelligent systems for healthcare.

---

## ğŸ¤ Contributions
Right now, this is a personal learning journey. If youâ€™re working on similar agent-based, feel free to connect!
